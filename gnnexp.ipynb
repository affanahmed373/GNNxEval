{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.explain.metric import fidelity,characterization_score,unfaithfulness\n",
    "dataset = 'Cora'\n",
    "path = 'data\\Planetoid'\n",
    "dataset = Planetoid(path, dataset)\n",
    "data = dataset[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['node_mask', 'edge_mask']\n",
      "Feature importance plot has been saved to 'feature_importance.png'\n",
      "Subgraph visualization plot has been saved to 'subgraph.pdf'\n"
     ]
    }
   ],
   "source": [
    "node_index = 10\n",
    "explanation = explainer(data.x, data.edge_index, index=node_index)\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "path = 'feature_importance.png'\n",
    "explanation.visualize_feature_importance(path, top_k=10)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")\n",
    "\n",
    "path = 'subgraph.pdf'\n",
    "explanation.visualize_graph(path)\n",
    "print(f\"Subgraph visualization plot has been saved to '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['node_mask', 'edge_mask']\n",
      "Fidelity: (0.0, 0.0)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     char_score \u001b[39m=\u001b[39m characterization_score(fid_pm[\u001b[39m0\u001b[39m], epsilon)\n\u001b[0;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     char_score \u001b[39m=\u001b[39m characterization_score(fid_pm[\u001b[39m0\u001b[39;49m], fid_pm[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCharacterization score:\u001b[39m\u001b[39m\"\u001b[39m, char_score)\n",
      "File \u001b[1;32me:\\thesis\\code\\streamlit\\.venv\\lib\\site-packages\\torch_geometric\\explain\\metric\\fidelity.py:131\u001b[0m, in \u001b[0;36mcharacterization_score\u001b[1;34m(pos_fidelity, neg_fidelity, pos_weight, neg_weight)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m (pos_weight \u001b[39m+\u001b[39m neg_weight) \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe weights need to sum up to 1 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(got \u001b[39m\u001b[39m{\u001b[39;00mpos_weight\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mneg_weight\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 131\u001b[0m denom \u001b[39m=\u001b[39m (pos_weight \u001b[39m/\u001b[39;49m pos_fidelity) \u001b[39m+\u001b[39m (neg_weight \u001b[39m/\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m neg_fidelity))\n\u001b[0;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m denom\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "fid_pm = fidelity(explainer, explanation)\n",
    "print(\"Fidelity:\", fid_pm)\n",
    "epsilon=0.99\n",
    "# x =torch.tensor([0,0.2,0.4,0.6, 0.8 , 1])\n",
    "if fid_pm[1]==1:\n",
    "    char_score = characterization_score(fid_pm[0], epsilon)\n",
    "else:\n",
    "    char_score = characterization_score(fid_pm[0], fid_pm[1])\n",
    "print(\"Characterization score:\", char_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfaithfulness1=unfaithfulness(explainer,explanation,top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22430866956710815\n"
     ]
    }
   ],
   "source": [
    "print(unfaithfulness1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
